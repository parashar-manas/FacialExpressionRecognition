{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parashar-manas/FacialExpressionRecognition/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5XuLxiCqTo5",
        "outputId": "228812e1-67d1-4400-9701-238b2f173cab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Facial-Expression-Dataset'...\n",
            "remote: Enumerating objects: 34052, done.\u001b[K\n",
            "remote: Total 34052 (delta 0), reused 0 (delta 0), pack-reused 34052\u001b[K\n",
            "Receiving objects: 100% (34052/34052), 52.31 MiB | 45.75 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (35887/35887), done.\n",
            "Collecting git+https://github.com/albumentations-team/albumentations\n",
            "  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-7tuh_b9m\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/albumentations-team/albumentations /tmp/pip-req-build-7tuh_b9m\n",
            "  Resolved https://github.com/albumentations-team/albumentations to commit e3b47b3a127f92541cfeb16abbb44a6f8bf79cc8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (0.0.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (4.7.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (4.8.0.76)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2.31.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2023.8.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (3.2.0)\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 timm-0.9.7\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# Clone the Facial Expression Dataset repository from GitHub\n",
        "!git clone https://github.com/parth1620/Facial-Expression-Dataset.git\n",
        "\n",
        "# Install or upgrade the Albumentations library using pip\n",
        "# Albumentations is a popular library for image augmentation techniques\n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations\n",
        "\n",
        "# Install the 'timm' library, which provides pre-trained models and model building utilities\n",
        "!pip install timm\n",
        "\n",
        "# Upgrade or install the OpenCV library with the contrib package\n",
        "# OpenCV is a powerful computer vision library, and the contrib package includes additional features\n",
        "!pip install --upgrade opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zefwrAnqsbZS"
      },
      "outputs": [],
      "source": [
        "# Import the NumPy library for numerical operations and array manipulation\n",
        "import numpy as np\n",
        "\n",
        "# Import the Matplotlib library for data visualization, particularly for creating plots and charts\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import the PyTorch library, a popular deep learning framework for building and training neural networks\n",
        "import torch\n",
        "\n",
        "# Import the PIL (Python Imaging Library) module for image processing tasks\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Import the torchvision.transforms module, which provides a collection of image transformation functions\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Import the ImageFolder dataset class from torchvision.datasets module\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Import the transforms module from torchvision, which provides image transformation functions\n",
        "from torchvision import transforms as T\n",
        "\n",
        "# Import the DataLoader class from the torch.utils.data module\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Import the 'timm' library, which provides pre-trained deep learning models\n",
        "import timm\n",
        "\n",
        "# Import the 'nn' module from PyTorch, which contains neural network building blocks\n",
        "from torch import nn\n",
        "\n",
        "# Import the 'tqdm' library for displaying progress bars during iterations\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DY8BPMpytC0b"
      },
      "outputs": [],
      "source": [
        "# Define the file path for the training images\n",
        "TRAIN_IMG_FOLDER_PATH = '/content/Facial-Expression-Dataset/train/'\n",
        "\n",
        "# Define the file path for the validation images\n",
        "VALID_IMG_FOLDER_PATH = '/content/Facial-Expression-Dataset/validation/'\n",
        "\n",
        "# Set the learning rate for training the model\n",
        "LP = 0.001\n",
        "\n",
        "# Set the batch size for training data\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Set the number of training epochs\n",
        "EPOCHS = 20\n",
        "\n",
        "# Specify the device for model training (e.g., 'cuda' for GPU or 'cpu' for CPU)\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# Specify the name of the model to be used (e.g., 'efficientnet_b0')\n",
        "MODEL_NAME = 'efficientnet_b0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MNRRWOnevo-A"
      },
      "outputs": [],
      "source": [
        "# Define a sequence of data augmentation transformations for training data\n",
        "train_augs = T.Compose([\n",
        "    # Randomly flip images horizontally with a 75% probability\n",
        "    T.RandomHorizontalFlip(p=0.75),\n",
        "\n",
        "    # Randomly rotate images within the range of -50 to +50 degrees\n",
        "    T.RandomRotation(degrees=(-50, +50)),\n",
        "\n",
        "    # Convert the augmented image to a PyTorch tensor\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Define a sequence of transformations for validation data\n",
        "valid_augs = T.Compose([\n",
        "    # Convert the validation image to a PyTorch tensor\n",
        "    T.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h8f9j4xZ0A6c"
      },
      "outputs": [],
      "source": [
        "# Create a training dataset using the ImageFolder class\n",
        "# The dataset is loaded from the TRAIN_IMG_FOLDER_PATH directory\n",
        "# The specified 'train_augs' transformations are applied to the images\n",
        "trainset = ImageFolder(TRAIN_IMG_FOLDER_PATH, transform=train_augs)\n",
        "\n",
        "# Create a validation dataset using the ImageFolder class\n",
        "# The dataset is loaded from the VALID_IMG_FOLDER_PATH directory\n",
        "# The specified 'valid_augs' transformations are applied to the images\n",
        "validset = ImageFolder(VALID_IMG_FOLDER_PATH, transform=valid_augs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neIR-Msy0x1G",
        "outputId": "c9f659fc-dd1a-467a-cbf0-2f8dbe31b7bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of examples in Trainset: 28821\n",
            "Total Number of examples in Validset: 7066\n"
          ]
        }
      ],
      "source": [
        "# Print the total number of examples in the training dataset\n",
        "print(f\"Total Number of examples in Trainset: {len(trainset)}\")\n",
        "\n",
        "# Print the total number of examples in the validation dataset\n",
        "print(f\"Total Number of examples in Validset: {len(validset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "Vnfr7fbZ1P2s",
        "outputId": "c5530434-e37c-4142-eddc-03ac4dafede0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Retrieve an image and its corresponding label from the training dataset (in this case, the 20th example)\n",
        "image, label = trainset[20]\n",
        "\n",
        "# Display the image using Matplotlib after permuting its dimensions to (height, width, channels)\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "\n",
        "# Set the title of the plot to the label of the image\n",
        "plt.title(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJGz-QT36b0w",
        "outputId": "a2f92093-c4be-46ee-d2e4-261c7546555e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
          ]
        }
      ],
      "source": [
        "# Print the class-to-index mapping in the training dataset\n",
        "print(trainset.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3wWKV6Zl-_Dj"
      },
      "outputs": [],
      "source": [
        "# Create a data loader for the training dataset\n",
        "# 'trainset' is the dataset to load from\n",
        "# 'BATCH_SIZE' specifies the batch size for loading data\n",
        "# 'shuffle=True' shuffles the data to ensure random order during training\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Create a data loader for the validation dataset\n",
        "# 'validset' is the dataset to load from\n",
        "# 'BATCH_SIZE' specifies the batch size for loading data\n",
        "# 'shuffle=True' shuffles the data to ensure random order during validation\n",
        "validloader = DataLoader(validset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO4oMwtwAVdz",
        "outputId": "8ee36ceb-e2dc-4f62-bf20-b8b1bcfb813d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of batches in Trainloader: 901\n",
            "Total Number of batches in Validloader: 221\n"
          ]
        }
      ],
      "source": [
        "# Print the total number of batches in the training data loader\n",
        "print(f\"Total Number of batches in Trainloader: {len(trainloader)}\")\n",
        "\n",
        "# Print the total number of batches in the validation data loader\n",
        "print(f\"Total Number of batches in Validloader: {len(validloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--no6h8IAxGO",
        "outputId": "22e781b1-7417-4b02-aebd-7077a87fffbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One image batch shape: torch.Size([32, 3, 48, 48])\n",
            "One label batch shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "# Iterate over the training data loader to retrieve one batch of images and labels\n",
        "for images, labels in trainloader:\n",
        "    break\n",
        "\n",
        "# Print the shape of one batch of images\n",
        "print(f\"One image batch shape: {images.shape}\")\n",
        "\n",
        "# Print the shape of one batch of labels\n",
        "print(f\"One label batch shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BO2cZhZbDUvV"
      },
      "outputs": [],
      "source": [
        "# Define a custom neural network model class called 'FaceModel'\n",
        "class FaceModel(nn.Module):\n",
        "\n",
        "    # Constructor method to initialize the model\n",
        "    def __init__(self):\n",
        "        super(FaceModel, self).__init__()\n",
        "\n",
        "        # Create an instance of the EfficientNet-B0 model with pretrained weights\n",
        "        self.eff_net = timm.create_model('efficientnet_b0', pretrained=True, num_classes=7)\n",
        "\n",
        "    # Forward method that defines the model's forward pass\n",
        "    def forward(self, images, labels=None):\n",
        "\n",
        "        # Pass the input images through the EfficientNet-B0 model\n",
        "        logits = self.eff_net(images)\n",
        "\n",
        "        if labels is not None:\n",
        "            # If labels are provided, compute the Cross-Entropy loss\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "            return logits, loss\n",
        "\n",
        "        # If labels are not provided, return the logits\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0126e5de17154119b5349490ae7a9266",
            "dc9c468e9eec4be4bb93cd41365e8629",
            "6261561d691244128a2add85f91ff938",
            "3ae59230537d432da86c538a9643c135",
            "ee92fb739ec64bbc99fcfebc98463f09",
            "5a7c30f2f61a458693547c178b19ab37",
            "23f8646b84d34c09881a60b33a39b15d",
            "bf051edcc28a4dc6bb809d295189a618",
            "2070f58f005b4876ae8a31f8b1aebba6",
            "a8b7de3aa1d240ada495b5d1f4eba232",
            "93adf32a96364483929fb2e928826b23"
          ]
        },
        "id": "c5kCRD1xOl4h",
        "outputId": "22ab8845-af42-47f8-8eff-478acd16ab2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0126e5de17154119b5349490ae7a9266"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FaceModel(\n",
              "  (eff_net): EfficientNet(\n",
              "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Create an instance of the 'FaceModel' class, which is a custom neural network model\n",
        "model = FaceModel()\n",
        "\n",
        "# Move the model to the specified device ('cuda' for GPU, 'cpu' for CPU)\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dNC7suZZSssg"
      },
      "outputs": [],
      "source": [
        "# Define a function to calculate the multi-class classification accuracy\n",
        "def multiclass_accuracy(y_pred, y_true):\n",
        "    # Get the predicted class with the highest probability for each example\n",
        "    top_p, top_class = y_pred.topk(1, dim=1)\n",
        "\n",
        "    # Compare the predicted class with the true class labels\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "\n",
        "    # Calculate the mean accuracy over all examples and return it\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ajXUDUN7Tav1"
      },
      "outputs": [],
      "source": [
        "# Define a function for training a deep learning model\n",
        "def train_fn(model, dataloader, optimizer, current_epo):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Initialize variables to keep track of total loss and total accuracy\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "\n",
        "    # Create a tqdm progress bar to display training progress\n",
        "    tk = tqdm(dataloader, desc=\"EPOCH [TRAIN] \" + str(current_epo + 1) + \"/\" + str(EPOCHS))\n",
        "\n",
        "    # Iterate over batches in the dataloader\n",
        "    for t, data in enumerate(tk):\n",
        "        images, labels = data\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        # Zero the gradients to prevent accumulation\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through the model and compute the loss\n",
        "        logits, loss = model(images, labels)\n",
        "\n",
        "        # Backpropagate the gradients and update the model's parameters\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the total loss and accuracy\n",
        "        total_loss += loss.item()\n",
        "        total_acc += multiclass_accuracy(logits, labels)\n",
        "\n",
        "        # Update the tqdm progress bar with loss and accuracy information\n",
        "        tk.set_postfix({'Loss': '%6f' % float(total_loss / (t + 1)), 'Accuracy': '%6f' % float(total_acc / (t + 1))})\n",
        "\n",
        "    # Calculate and return the average loss and accuracy for the epoch\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zCwVqnMCWdqv"
      },
      "outputs": [],
      "source": [
        "# Define a function for evaluating a deep learning model\n",
        "def eval_fn(model, dataloader, current_epo):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize variables to keep track of total loss and total accuracy\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "\n",
        "    # Create a tqdm progress bar to display evaluation progress\n",
        "    tk = tqdm(dataloader, desc=\"EPOCH [VALID] \" + str(current_epo + 1) + \"/\" + str(EPOCHS))\n",
        "\n",
        "    # Iterate over batches in the dataloader\n",
        "    for t, data in enumerate(tk):\n",
        "        images, labels = data\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        # Forward pass through the model and compute the loss\n",
        "        logits, loss = model(images, labels)\n",
        "\n",
        "        # Update the total loss and accuracy\n",
        "        total_loss += loss.item()\n",
        "        total_acc += multiclass_accuracy(logits, labels)\n",
        "\n",
        "        # Update the tqdm progress bar with loss and accuracy information\n",
        "        tk.set_postfix({'Loss': '%6f' % float(total_loss / (t + 1)), 'Accuracy': '%6f' % float(total_acc / (t + 1))})\n",
        "\n",
        "    # Calculate and return the average loss and accuracy for the epoch\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "49S6J-TzW453"
      },
      "outputs": [],
      "source": [
        "# Initialize the Adam optimizer for the model's parameters\n",
        "# 'model.parameters()' provides the parameters to be optimized\n",
        "# 'lr=LP' sets the learning rate to the value stored in the 'LP' variable\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBIj0D3Zdodn",
        "outputId": "88c5bc40-0722-438b-d036-372a4d8619ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 1/20: 100%|██████████| 901/901 [00:47<00:00, 18.86it/s, Loss=1.902528, Accuracy=0.346307]\n",
            "EPOCH [VALID] 1/20: 100%|██████████| 221/221 [00:06<00:00, 34.56it/s, Loss=1.409004, Accuracy=0.462496]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 2/20: 100%|██████████| 901/901 [00:45<00:00, 19.99it/s, Loss=1.384079, Accuracy=0.469383]\n",
            "EPOCH [VALID] 2/20: 100%|██████████| 221/221 [00:06<00:00, 35.05it/s, Loss=1.264470, Accuracy=0.513923]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 3/20: 100%|██████████| 901/901 [00:44<00:00, 20.05it/s, Loss=1.281947, Accuracy=0.512532]\n",
            "EPOCH [VALID] 3/20: 100%|██████████| 221/221 [00:06<00:00, 35.38it/s, Loss=1.175353, Accuracy=0.544324]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 4/20: 100%|██████████| 901/901 [00:45<00:00, 19.99it/s, Loss=1.223149, Accuracy=0.533078]\n",
            "EPOCH [VALID] 4/20: 100%|██████████| 221/221 [00:06<00:00, 35.80it/s, Loss=1.141472, Accuracy=0.567047]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 5/20: 100%|██████████| 901/901 [00:45<00:00, 19.66it/s, Loss=1.184908, Accuracy=0.551170]\n",
            "EPOCH [VALID] 5/20: 100%|██████████| 221/221 [00:05<00:00, 39.04it/s, Loss=1.108644, Accuracy=0.579523]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 6/20: 100%|██████████| 901/901 [00:45<00:00, 19.60it/s, Loss=1.164251, Accuracy=0.562041]\n",
            "EPOCH [VALID] 6/20: 100%|██████████| 221/221 [00:05<00:00, 39.96it/s, Loss=1.088244, Accuracy=0.589497]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 7/20: 100%|██████████| 901/901 [00:45<00:00, 19.68it/s, Loss=1.133738, Accuracy=0.570969]\n",
            "EPOCH [VALID] 7/20: 100%|██████████| 221/221 [00:05<00:00, 40.11it/s, Loss=1.142362, Accuracy=0.582938]\n",
            "EPOCH [TRAIN] 8/20: 100%|██████████| 901/901 [00:45<00:00, 19.62it/s, Loss=1.113536, Accuracy=0.578621]\n",
            "EPOCH [VALID] 8/20: 100%|██████████| 221/221 [00:06<00:00, 36.02it/s, Loss=1.137129, Accuracy=0.585777]\n",
            "EPOCH [TRAIN] 9/20: 100%|██████████| 901/901 [00:45<00:00, 19.91it/s, Loss=1.089106, Accuracy=0.591922]\n",
            "EPOCH [VALID] 9/20: 100%|██████████| 221/221 [00:06<00:00, 35.26it/s, Loss=1.041295, Accuracy=0.601342]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 10/20: 100%|██████████| 901/901 [00:44<00:00, 20.18it/s, Loss=1.064112, Accuracy=0.597919]\n",
            "EPOCH [VALID] 10/20: 100%|██████████| 221/221 [00:06<00:00, 35.50it/s, Loss=1.082983, Accuracy=0.585744]\n",
            "EPOCH [TRAIN] 11/20: 100%|██████████| 901/901 [00:44<00:00, 20.13it/s, Loss=1.043648, Accuracy=0.608502]\n",
            "EPOCH [VALID] 11/20: 100%|██████████| 221/221 [00:06<00:00, 35.02it/s, Loss=1.064890, Accuracy=0.604420]\n",
            "EPOCH [TRAIN] 12/20: 100%|██████████| 901/901 [00:45<00:00, 19.92it/s, Loss=1.022766, Accuracy=0.612781]\n",
            "EPOCH [VALID] 12/20: 100%|██████████| 221/221 [00:05<00:00, 37.88it/s, Loss=1.015652, Accuracy=0.616048]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 13/20: 100%|██████████| 901/901 [00:45<00:00, 19.76it/s, Loss=1.001345, Accuracy=0.624372]\n",
            "EPOCH [VALID] 13/20: 100%|██████████| 221/221 [00:05<00:00, 39.13it/s, Loss=1.032031, Accuracy=0.618952]\n",
            "EPOCH [TRAIN] 14/20: 100%|██████████| 901/901 [00:45<00:00, 19.60it/s, Loss=0.986619, Accuracy=0.629309]\n",
            "EPOCH [VALID] 14/20: 100%|██████████| 221/221 [00:05<00:00, 39.46it/s, Loss=1.039813, Accuracy=0.608478]\n",
            "EPOCH [TRAIN] 15/20: 100%|██████████| 901/901 [00:45<00:00, 19.69it/s, Loss=0.964458, Accuracy=0.636266]\n",
            "EPOCH [VALID] 15/20: 100%|██████████| 221/221 [00:05<00:00, 38.85it/s, Loss=1.032816, Accuracy=0.612644]\n",
            "EPOCH [TRAIN] 16/20: 100%|██████████| 901/901 [00:45<00:00, 19.64it/s, Loss=0.952105, Accuracy=0.642509]\n",
            "EPOCH [VALID] 16/20: 100%|██████████| 221/221 [00:06<00:00, 35.50it/s, Loss=1.037042, Accuracy=0.616396]\n",
            "EPOCH [TRAIN] 17/20: 100%|██████████| 901/901 [00:45<00:00, 19.86it/s, Loss=0.930886, Accuracy=0.653123]\n",
            "EPOCH [VALID] 17/20: 100%|██████████| 221/221 [00:06<00:00, 35.02it/s, Loss=1.014002, Accuracy=0.622063]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH [TRAIN] 18/20: 100%|██████████| 901/901 [00:45<00:00, 20.02it/s, Loss=0.910361, Accuracy=0.658465]\n",
            "EPOCH [VALID] 18/20: 100%|██████████| 221/221 [00:06<00:00, 35.22it/s, Loss=1.017160, Accuracy=0.625098]\n",
            "EPOCH [TRAIN] 19/20: 100%|██████████| 901/901 [00:44<00:00, 20.12it/s, Loss=0.896508, Accuracy=0.664014]\n",
            "EPOCH [VALID] 19/20: 100%|██████████| 221/221 [00:06<00:00, 36.08it/s, Loss=1.028355, Accuracy=0.622553]\n",
            "EPOCH [TRAIN] 20/20: 100%|██████████| 901/901 [00:45<00:00, 19.81it/s, Loss=0.883211, Accuracy=0.673569]\n",
            "EPOCH [VALID] 20/20: 100%|██████████| 221/221 [00:05<00:00, 38.57it/s, Loss=1.004343, Accuracy=0.627317]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED-BEST-WEIGHTS\n"
          ]
        }
      ],
      "source": [
        "# Initialize a variable to store the best validation loss as positive infinity\n",
        "best_valid_loss = np.Inf\n",
        "\n",
        "# Iterate over the specified number of training epochs\n",
        "for i in range(EPOCHS):\n",
        "    # Train the model for one epoch and calculate training loss and accuracy\n",
        "    train_loss, train_acc = train_fn(model, trainloader, optimizer, i)\n",
        "\n",
        "    # Evaluate the model on the validation dataset for one epoch and calculate validation loss and accuracy\n",
        "    valid_loss, valid_acc = eval_fn(model, validloader, i)\n",
        "\n",
        "    # Check if the current validation loss is better (lower) than the best validation loss so far\n",
        "    if valid_loss < best_valid_loss:\n",
        "        # Save the model's state dictionary to 'best-weights.pt'\n",
        "        torch.save(model.state_dict(), 'best-weights.pt')\n",
        "        print(\"SAVED-BEST-WEIGHTS\")\n",
        "        # Update the best validation loss with the current validation loss\n",
        "        best_valid_loss = valid_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for visualizing image classification results\n",
        "def view_classify(img, ps):\n",
        "    # Define a list of class names corresponding to the output classes\n",
        "    classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "    # Convert the predicted probabilities to a NumPy array and remove the extra dimensions\n",
        "    ps = ps.data.cpu().numpy().squeeze()\n",
        "\n",
        "    # Convert the image tensor to a NumPy array and transpose it to the correct format\n",
        "    img = img.numpy().transpose(1, 2, 0)\n",
        "\n",
        "    # Create a figure with two subplots for displaying the image and class probabilities\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(5, 9), ncols=2)\n",
        "\n",
        "    # Display the image on the left subplot and remove axis labels\n",
        "    ax1.imshow(img)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Create a horizontal bar chart on the right subplot to visualize class probabilities\n",
        "    ax2.barh(classes, ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(classes)\n",
        "    ax2.set_yticklabels(classes)\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    # Ensure a tight layout for better visualization\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Return None (this function is used for visualization purposes)\n",
        "    return None"
      ],
      "metadata": {
        "id": "K66rXjIfMH3v"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path for the image\n",
        "image_path = '/content/download (2).jpeg'\n",
        "\n",
        "# Open and load the image using PIL\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Convert the image to grayscale using ImageOps\n",
        "bw_image = ImageOps.grayscale(image)\n",
        "\n",
        "# Define a series of image transformation operations using torchvision transforms\n",
        "resize_transform = T.Compose([\n",
        "    # Resize the image to a specified size (48x48 pixels)\n",
        "    T.Resize((48, 48)),\n",
        "\n",
        "    # Convert the image to grayscale with three channels\n",
        "    T.Grayscale(num_output_channels=3),\n",
        "\n",
        "    # Convert the image to a PyTorch tensor\n",
        "    T.ToTensor(),\n",
        "\n",
        "    # Normalize the image using specified mean and standard deviation values\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Apply the defined transformations to the input image and unsqueeze it to add a batch dimension\n",
        "input_image = resize_transform(image).unsqueeze(0)\n",
        "\n",
        "# Move the input image to the specified device (e.g., 'cuda' for GPU)\n",
        "input_image = input_image.to(DEVICE)\n",
        "\n",
        "# Disable gradient tracking and set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "\n",
        "    # Perform forward pass on the input image to obtain model predictions\n",
        "    output = model(input_image)\n",
        "\n",
        "# Move the model predictions and input image back to the CPU for visualization\n",
        "output = output.cpu()\n",
        "input_image = input_image.cpu()\n",
        "\n",
        "# Use the 'view_classify' function to visualize the classification results\n",
        "view_classify(input_image[0], torch.softmax(output, dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "YUsGT3pgxAGV",
        "outputId": "dafc4644-8365-4ff8-f421-b2f0a2970d88"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x900 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOp4ZOYhtAxo4KTPy5x+FyQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0126e5de17154119b5349490ae7a9266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc9c468e9eec4be4bb93cd41365e8629",
              "IPY_MODEL_6261561d691244128a2add85f91ff938",
              "IPY_MODEL_3ae59230537d432da86c538a9643c135"
            ],
            "layout": "IPY_MODEL_ee92fb739ec64bbc99fcfebc98463f09"
          }
        },
        "dc9c468e9eec4be4bb93cd41365e8629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7c30f2f61a458693547c178b19ab37",
            "placeholder": "​",
            "style": "IPY_MODEL_23f8646b84d34c09881a60b33a39b15d",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "6261561d691244128a2add85f91ff938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf051edcc28a4dc6bb809d295189a618",
            "max": 21355344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2070f58f005b4876ae8a31f8b1aebba6",
            "value": 21355344
          }
        },
        "3ae59230537d432da86c538a9643c135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b7de3aa1d240ada495b5d1f4eba232",
            "placeholder": "​",
            "style": "IPY_MODEL_93adf32a96364483929fb2e928826b23",
            "value": " 21.4M/21.4M [00:00&lt;00:00, 70.3MB/s]"
          }
        },
        "ee92fb739ec64bbc99fcfebc98463f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a7c30f2f61a458693547c178b19ab37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23f8646b84d34c09881a60b33a39b15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf051edcc28a4dc6bb809d295189a618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2070f58f005b4876ae8a31f8b1aebba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8b7de3aa1d240ada495b5d1f4eba232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93adf32a96364483929fb2e928826b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}